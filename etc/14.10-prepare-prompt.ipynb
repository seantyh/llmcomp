{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c5f9511-19a4-4273-a1b6-f7aaef0e3a5c",
   "metadata": {},
   "source": [
    "## Data dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4539ffc4-1366-4cd3-b660-00791a6ec7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ef1e20540a9724ef89f4da60dd883eb6993d60c  ../data/pwn_semrel_pairs.json\n"
     ]
    }
   ],
   "source": [
    "!sha1sum ../data/pwn_semrel_pairs.json  # from 12.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0457a4d-eef7-475d-81a2-a17d1b29f9d9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70eaeb28-8266-4607-8cc6-b24b191be528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from io import StringIO\n",
    "from itertools import chain\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b1b625-0377-4248-b82a-cb3532d016f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwn_pairs = json.loads(Path(\"../data/pwn_semrel_pairs.json\").read_text())\n",
    "hypernym_pairs = pwn_pairs[\"hypernymy\"]\n",
    "holonym_pairs = pwn_pairs[\"holonymy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3117a0c1-1538-420e-abfa-3824b0998424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1285, 164)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hypernym_pairs), len(holonym_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e969b44b-b3fe-4164-8d7c-a743218d8414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_task_prompt_base = \"\"\"\n",
    "The definition of \"{a_lemma}\" is {a_def}\n",
    "The {semrel} of the word \"{a_lemma}\" is {b_lemma}: {b_def}\n",
    "\"\"\"\n",
    "\n",
    "def get_lemma_def(synid):\n",
    "    syn_x = wn.synset(synid)\n",
    "    x_lemma = syn_x.lemmas()[0].name()\n",
    "    x_def = syn_x.definition()\n",
    "    return x_lemma, x_def\n",
    "    \n",
    "def build_prompt(fstring, **kwargs):\n",
    "    var_locations = []\n",
    "    formatted_string = StringIO()    \n",
    "    while match:=re.search(r'\\{(\\w+)\\}', fstring):\n",
    "        var_name = match.group(1)\n",
    "        var_value = str(kwargs[var_name])  \n",
    "        \n",
    "        formatted_string.write(fstring[:match.start()])\n",
    "        var_start = formatted_string.tell()\n",
    "        formatted_string.write(var_value)\n",
    "        var_end = formatted_string.tell()\n",
    "        var_locations.append((var_name, var_value, var_start, var_end))\n",
    "        fstring = fstring[match.end():]    \n",
    "    formatted_string.write(fstring)\n",
    "\n",
    "    ## check var_locations\n",
    "    outstr = formatted_string.getvalue()\n",
    "    for _, val, si, ei in var_locations:\n",
    "        assert outstr[si:ei] == val\n",
    "        \n",
    "    return outstr, var_locations\n",
    "\n",
    "def prompt_from_semrel(semrel, pair):\n",
    "    assert semrel in (\"hypernym\", \"holonym\")\n",
    "    a, b = pair\n",
    "    up_lemma, up_def = get_lemma_def(a)\n",
    "    low_lemma, low_def = get_lemma_def(b)\n",
    "    \n",
    "    prompt, var_loc = build_prompt(\n",
    "        def_task_prompt_base.strip(), \n",
    "        semrel=semrel, a_lemma=low_lemma, a_def=low_def, b_lemma=up_lemma, b_def=up_def)    \n",
    "    return prompt, var_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af8eab6f-5e22-411d-9c39-35bfe77068e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The definition of \"forfeit\" is lose (s.th.) or lose the right to (s.th.) by some error, offense, or crime\\nThe hypernym of the word \"forfeit\" is abandon: forsake, leave behind',\n",
       " [('a_lemma', 'forfeit', 19, 26),\n",
       "  ('a_def',\n",
       "   'lose (s.th.) or lose the right to (s.th.) by some error, offense, or crime',\n",
       "   31,\n",
       "   105),\n",
       "  ('semrel', 'hypernym', 110, 118),\n",
       "  ('a_lemma', 'forfeit', 132, 139),\n",
       "  ('b_lemma', 'abandon', 144, 151),\n",
       "  ('b_def', 'forsake, leave behind', 153, 174)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_from_semrel(\"hypernym\", hypernym_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dacc1c5-2793-49ce-907a-2543be9d6028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The definition of \"scene\" is a subdivision of an act of a play\\nThe holonym of the word \"scene\" is act: a subdivision of a play or opera or ballet',\n",
       " [('a_lemma', 'scene', 19, 24),\n",
       "  ('a_def', 'a subdivision of an act of a play', 29, 62),\n",
       "  ('semrel', 'holonym', 67, 74),\n",
       "  ('a_lemma', 'scene', 88, 93),\n",
       "  ('b_lemma', 'act', 98, 101),\n",
       "  ('b_def', 'a subdivision of a play or opera or ballet', 103, 145)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_from_semrel(\"holonym\", holonym_pairs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b096758-6155-4af3-95a0-7d142b954fee",
   "metadata": {},
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d87cabb-72f9-4fbd-8461-0ee52f36515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_pairs(data_pairs, rng):\n",
    "    \"\"\"\n",
    "    Shuffles the first element of each pair in a list of data pairs randomly.\n",
    "\n",
    "    Args:\n",
    "        data_pairs (list): A list of pairs, where each pair is a tuple of two elements.\n",
    "\n",
    "    Returns:\n",
    "        list: A new list of pairs, where each pair is a tuple of two elements. The first element of each pair\n",
    "        is shuffled randomly.\n",
    "    \"\"\"    \n",
    "    shuffle_hypers = data_pairs[::1]\n",
    "    rng.shuffle(shuffle_hypers)\n",
    "    ori_b_list = [x[1] for x in data_pairs]\n",
    "    perm_a_list = [x[0] for x in shuffle_hypers]\n",
    "    perm_data_pairs = [(a,b) for a,b in zip(perm_a_list, ori_b_list)]\n",
    "    return perm_data_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc937605-dd02-4071-8e40-ec5af05c72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.Random(123)\n",
    "perm_hypernym_pairs = shuffle_pairs(hypernym_pairs, rng)\n",
    "perm_holonym_pairs = shuffle_pairs(holonym_pairs, rng)\n",
    "datalist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93706763-f6ad-4c92-a318-82bc7bc63870",
   "metadata": {},
   "source": [
    "### build hypernym pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a670eafc-53a2-4a09-9837-10bbd2ccf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair_x in hypernym_pairs:\n",
    "    prompt, var_loc = prompt_from_semrel(\"hypernym\", pair_x)\n",
    "    datalist.append({\n",
    "        \"semrel\": \"hypernym\",\n",
    "        \"type\": \"emp\",\n",
    "        \"pair\": list(pair_x),\n",
    "        \"prompt\": prompt,\n",
    "        \"var_loc\": var_loc        \n",
    "    })\n",
    "\n",
    "for pair_x in perm_hypernym_pairs:\n",
    "    prompt, var_loc = prompt_from_semrel(\"hypernym\", pair_x)\n",
    "    datalist.append({\n",
    "        \"semrel\": \"hypernym\",\n",
    "        \"type\": \"perm\",\n",
    "        \"pair\": list(pair_x),\n",
    "        \"prompt\": prompt,\n",
    "        \"var_loc\": var_loc        \n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c955cc8a-6539-4cbe-a781-5a4fa8223f0d",
   "metadata": {},
   "source": [
    "### build holonym pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08449a34-8fd7-448d-8d0a-cf8e071bfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for pair_x in holonym_pairs:\n",
    "    prompt, var_loc = prompt_from_semrel(\"holonym\", pair_x)\n",
    "    datalist.append({\n",
    "        \"semrel\": \"holonym\",\n",
    "        \"type\": \"emp\",\n",
    "        \"pair\": list(pair_x),\n",
    "        \"prompt\": prompt,\n",
    "        \"var_loc\": var_loc        \n",
    "    })\n",
    "\n",
    "for pair_x in perm_holonym_pairs:\n",
    "    prompt, var_loc = prompt_from_semrel(\"holonym\", pair_x)\n",
    "    datalist.append({\n",
    "        \"semrel\": \"holonym\",\n",
    "        \"type\": \"perm\",\n",
    "        \"pair\": list(pair_x),\n",
    "        \"prompt\": prompt,\n",
    "        \"var_loc\": var_loc        \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0357cc30-7c63-4a03-8a26-839ea0a77560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5236da3d32f4a5a1afe42eedc40e1a0fe7b87edc  ../data/pwn_semrel_dataset.json\n"
     ]
    }
   ],
   "source": [
    "out_path = Path(\"../data/pwn_semrel_dataset.json\")\n",
    "out_path.write_text(json.dumps(datalist))\n",
    "!sha1sum {str(out_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34942074-7302-4433-8ac0-11fc93cc87aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
